%  INTERIM REPORT TEMPLATE (XeLaTeX)

\documentclass[12pt,a4paper]{article}
\usepackage[a4paper,margin=1in]{geometry}
\usepackage{csquotes}
\usepackage{lmodern}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\hypersetup{colorlinks=true, linkcolor=black, urlcolor=blue}

%---- Headers/footers (page numbers) ----%
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}                    % clear header/footer
\fancyfoot[C]{\thepage}      % page number centered in footer
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}

%---- Heading formatting (Header 1 & 2) ----%
% Header 1 (Chapter-level): 14pt, bold
\makeatletter
\renewcommand\section{\@startsection{section}{1}{\z@}%
  {-3.5ex \@plus-1ex \@minus-.2ex}%
  {2.3ex \@plus.2ex}%
  {\normalfont\large\bfseries}}
\makeatother
% Header 2 (subsection): 12pt, bold
\makeatletter
\renewcommand\subsection{\@startsection{subsection}{2}{\z@}%
  {-3.25ex\@plus-1ex \@minus-.2ex}%
  {1.5ex \@plus.2ex}%
  {\normalfont\normalsize\bfseries}}
\makeatother

%---- User macros (fill these once) ----%
\newcommand{\CourseCodeNumber}{CSC4046 }
\newcommand{\CourseCodeName}{Individual Research Project}
\newcommand{\ProjectTitle}{Interpretable Deep Learning for Robust Drug Mechanism Prediction in High-Throughput Gene Expression Data}
\newcommand{\StudentName}{Navinda Hewawickrama}
\newcommand{\RegistrationNumber}{SC/2020/11730} % <-- change this
\newcommand{\Supervisors}{Dr.Sugandima Vidanagamachchi} % add more if needed
\newcommand{\SubmissionDate}{October 2025}
\newcommand{\CoverImagePath}{RUHUNAPNG} % <-- set your image file name here

\begin{document}
%======================%
%  COVER PAGE
%======================%
\begin{titlepage}
  \thispagestyle{empty} 
  \begin{center}
    \vspace*{10mm}
    {\Large \textbf{\CourseCodeNumber}}\\[6mm]
    {\Large \textbf{\CourseCodeName}}\\[6mm]
    \includegraphics[width=0.5\textwidth]{\CoverImagePath}\\[10mm]
    
    {\Large \textbf{\ProjectTitle}}\\[10mm]

    % Cover image (optional). Replace width as you like.
    

    \textbf{Registration No.:} \RegistrationNumber\\[2mm]
    \textbf{Student Name:} \StudentName\\[6mm]
    \textbf{Supervisor(s):} \Supervisors\\[10mm]

    \SubmissionDate\\[12mm]

    \vfill
    \textbf{Bachelor of Computer Science (Special) Degree}\\
    Department of Computer Science, University of Ruhuna
  \end{center}
\end{titlepage}

% start page numbering from here
\clearpage
\pagenumbering{arabic}

%======================%
%  CONTENT OF THE REPORT
%======================%

%--- Chapter 1 ---%
\section{Introduction}

\subsection{Introduction}
Data-driven mechanisms of action (MoA) prediction is made possible by the large-scale, huge drug-cell response profiles provided by high-throughput perturbational transcriptomics, especially the LINCS L1000 collection. However, in practice, these datasets are very difficult to use consistently because of a combination of inherent technical/inferential noise (most landmark genes are inferred, while only 978 are directly measured), batch and assay artefacts, and frequent gaps or inconsistencies in metadata. These factors collectively weaken model generalisation and reduce reproducibility. However, integrating transcriptome signals with external data like drug chemical structure, protein-protein interaction networks, and Gene Ontology hierarchies is both beneficial and challenging, requiring careful representation learning and cross-modal alignment\cite{subramanian2017next,stathias2018sustainable,mcdermott2019deep,wu2022deep}

In order to address these problems, this project (i) Critically examines previous and present computational pipelines for L1000-based MoA prediction in order identify failure modes and best practices (ii) In order to improve interpretability and generalisation, a modular, reproducible framework that simplifies data-centric cleaning and metadata consistency, integrates robust/model-centric training procedures, and incorporates external biological knowledge is proposed. Explainable AI is a key focus, in addition to attaining high accuracy, we want to make model reasoning auditable by connecting predictions to pharmacological substructures, genes, and pathways, making the resulting MoA hypotheses easier to evaluate and scientifically significant\cite{duan2016l1000cds2,stahlschmidt2022multimodal,samal2022opportunities}


\subsection{Problem Definition}
The main obstacle to using the LINCS L1000 dataset for drug development is that, although many computer models are capable of achieving high predicted accuracy, their interpretability and robustness are frequently lacking, which restricts their application in clinical settings.  There is a need for a comprehensive solution because previous research has frequently addressed these issues separately.\\
These are our original research questions:
\begin{itemize}  
  \item \textbf{R1:} What techniques have been used to predict drug mechanisms of action from LINCS gene expression data, and how do they balance accuracy, scalability, and interpretability, in high-dimensional biomedical contexts?
  \item \textbf{R2:} How do data quality issues (e.g., noise, inconsistencies) affect the performance and generalizability of predictive models, and what computational methods have been used to address these challenges?
  \item \textbf{R3:} Are there frameworks that effectively integrate external knowledge (e.g., drug structures, biological networks) with transcriptomic data, and how do they impact model interpretability, generalizability, and explainability?
\end{itemize}

R1 compares techniques about accuracy, scalability, interpretability trade-offs. R2 quantifies the impact of data quality and evaluates mitigation strategies. R3 studies how integrating external knowledge can imprive the interpretability and generalization of the model.


\noindent
These problems motivate our research questions:
\\

\textbf{1. The Robustness Problem (R2/R1):}Standard machine learning models are highly sensitive to the technical noise, batch effects, and data inconsistencies inherent in the L1000 platform. This leads to models that do not generalize well to new data, making their predictions unreliable. Models, classical and deep, are sensitive to structured technical and annotation noise in L1000 (e.g., deconvolution errors, inferred genes, batch effects, metadata gaps), which degrades out-of-distribution (OOD) generalization and reliability.
\\
\textbf{2. The Context Problem (R3/R1):}Models relying only on gene expression data lack biological context. Their predictions are often correlational rather than mechanistic, failing to explain why a drug has a certain effect based on underlying biological pathways.Expression-only models capture correlations but lack mechanistic context. Without integrating drug structure and biological networks (PPIs, Gene Ontology), predictions do not explain \emph{why} an effect occurs.
\\
\textbf{3. The Trust Problem (R1/R3):}The increasing complexity of deep learning models results in \enquote{black boxes}.For clinicians and biologists, a prediction is not actionable if its underlying reasoning cannot be understood, audited, and trusted. State-of-the-art models are often black boxes. Actionable use requires understandable explanations that are faithful to the model, biologically grounded (pathways/targets), and reproducible.
\\
\noindent
Thus, the main issue this study attempts to solve is the absence of a single computational framework that simultaneously guarantees resilience against data noise, incorporates outside biological knowledge for mechanistic background, and makes its predictions easily interpretable.

\subsection{Objective of the Research}\label{subsec:Objective of the Research}
The primary objective of this research is to design, develop, and evaluate a novel, end-to-end computational framework that significantly improves the robustness, biological relevance, and interpretability of drug Mechanism of Action (MoA) prediction from LINCS L1000 data.To achieve this overarching goal, the research is guided by the following specific objectives (derived from the corresponding research questions R1, R2, and R3).
\\ 
\\
\textbf{Objective 1: To Define Optimal Performance and Interpretability Trade-offs (R1)} First, to conduct a systematic literature review of existing methods,including classic machine learning (ML), Multi-Layer Perceptrons (MLPs), Graph Neural Networks (GNNs), and attention/Transformer architectures, to establish a performance baseline, critically analyze their strengths and weaknesses, and identify best practices for working with LINCS L1000 data. This objective focuses on balancing accuracy, scalability, and interpretability within high-dimensional biomedical contexts, providing a robust performance baseline for the final framework.
\\
\textbf{Objective 2: To Enhance Robustness and Mitigate Data Quality Issues (R2)} To design a data preprocessing pipeline that reduces and mitigates noise and corrects inconsistencies, such as technical/inferential noise, batch effects, and metadata inconsistencies, in the L1000 dataset. This involves integrating external knowledge from biological databases (e.g., protein-protein interaction networks) using graph-based methods to enrich the gene expression features and fill metadata gaps.
\\
\textbf{Objective 3: To Ground Predictions in Mechanistic Biological Context (R3)} To overcome the \enquote{Context Problem}, we aim to design and implement knowledge-infused deep learning architectures that integrate external biological knowledge. This involves leveraging graph-based methods to fuse multi-modal data, such as drug chemical structure, Protein-Protein Interaction (PPI) networks, and Gene Ontology (GO) hierarchies, thereby enhancing mechanistic interpretability and generalizability.
\\
\textbf{Objective 4: To Deliver Transparent and Auditable Explanations (XAI)} To integrate Explainable AI (XAI) techniques into the framework. The goal is not only to achieve high accuracy but also to make the model’s predictions transparent, allowing researchers to understand the underlying biological drivers (e.g., key genes, pathways) behind its decisions.

\subsection{Scope of the Research}
In particular, the LINCS L1000 dataset analysis is the main focus of this study.  There are more transcriptome datasets, but they are considered outside the purview of this project's main analysis and framework creation. The main objective is to anticipate the Mechanism of Action (MoA) of a medicine.  External knowledge will only be incorporated into the suggested computational framework from publicly accessible biological resources, such as the Gene Ontology (GO) hierarchy and the STRING database for protein-protein interactions.
\\
The primary deliverables for this project are:
\begin{itemize}
  \item A comprehensive Systematic Literature Review (SLR) manuscript that establishes a baseline of current methods.
  \item A novel computational framework that integrates data preprocessing, knowledge infusion, and a predictive deep learning model.
  \item A trained and evaluated deep learning model for MoA prediction, complete with interpretability analyses.
  \item A final research thesis detailing the project's methodology, results, and conclusions.
\end{itemize}
Some key assumptions are made when operating the project.\\
(i) that the biological annotations from external databases are sufficiently accurate to provide meaningful context\\ (ii) that a learnable signal correlating to drug MoA exists within the noisy L1000 data and\\(iii) that the 978 landmark genes serve as an effective proxy for the full transcriptome
The research is bound by several constraints, including the computational resources (GPU/CPU time) available for training complex models, and the inherent limitations in the \enquote{ground truth} MoA labels, which can be incomplete or ambiguous.


%--- Chapter 2 ---%
\section{Literature Review}
This review looks at methods for predicting drug mechanisms of action (MoA) from LINCS/CMap (L1000) transcriptomic data, organized along three themes that showcase our research questions: \\(R1) Techniques and the accuracy, scalability, interpretability trade-off \\ (R2) Data-quality issues and mitigation; and \\(R3) Integration of external biological knowledge for contextual, auditable predictions.

\subsection{Early Approaches: Signature Similarity \& Classical ML (R1)}
According to the Connectivity Map concept, medications with comparable gene-expression profiles have similar molecular patterns.  Large retrieval operations were made possible by the availability of scalable profiles (MODZ-aggregated signatures) by the next-generation CMap/L1000\cite{subramanian2017next}. To improve signal quality, Characteristic Direction (CD) signatures replaced naive fold-change or $t$-statistics, yielding more accurate reversal/connection performance\cite{duan2016l1000cds2}. Traditional machine learning (ML) baselines (RF, SVM, regularised logistic/XGBoost) became competitive as datasets increased. Optimised pipelines like WRFEN, XGBoost demonstrate that resilient learners and good feature engineering may compete with deeper models on certain specific tasks\cite{lu2021drug}.\\
\textbf{Strengths:} simple, fast, interpretable (feature importance); scalable screening.
\textbf{Weaknesses:} Has limitations in nonlinearity, struggle with high-dimensional patterns and cross-context generalization.

\subsection{Deep Learning: MLPs, GNNs, Attention/Transformers (R1)}
Benchmarks show multilayer perceptrons (MLPs) typically perform better than classical baselines on L1000 tasks, but transparency is the cost of that performance\cite{mcdermott2019deep}. Knowledge-aware Graph CNNs (GNNs) constrain learning to biological topology (e.g., PPI), promoting pathway-aligned features—promising on large data, but sometimes outperformed by MLPs on smaller collections\cite{mcdermott2019deep}. Recent work shows and uses attention/Transformers for cross-context modeling. DeepCE aligns drug substructures with gene effects, improving accuracy and offering substructure, gene attributions\cite{pham2021deep}, while MultiDCP uses knowledge-aware Transformers to generalize across cell types and even outperform noisy experimental baselines in some settings\cite{wu2022deep}.\\
\textbf{Strengths:} higher accuracy, flexible representation learning, phas the otential of cross-context generalization.
\textbf{Weaknesses:} opacity (\enquote{black boxes}), data-hungry, sensitive to dataset noise if not handled explicitly.

\subsection{Data Quality in L1000 \& Mitigation (R2)}
In addition to batch/assay artefacts and metadata inconsistencies, L1000 introduces inferential noise while measuring 978 landmark genes and computationally calculating the remaining genes\cite{subramanian2017next,mcdermott2019deep}. Peak-calling/deconvolution instabilities in the original pipeline have motivated GMM/AGMM and Bayesian deconvolution, which reduce errors\cite{qiu2020bayesian}. Replicate-correlation filtering and better signature generation (e.g., CD) increase signal-to-noise while model-guided augmentation can salvage high-quality replicates which are flagged as noisy\cite{szalai2019signatures,duan2016l1000cds2,pham2021deep}. Sensitivity to label and feature noise is enhanced on the model side by semi-/self-supervised pretraining, resilient losses, and co-teaching/curriculum learning.\\
\textbf{Strengths:} measurable SNR gains, improved reproducibility and downstream accuracy.
\textbf{Weaknesses:} heterogeneous, structured noise remains challenging, label/metadata gaps are non-trivial to repair at scale.

\subsection{Knowledge Integration for Context \& Interpretability (R3)}
Expression alone provides correlations, not mechanisms. Integrating drug structure and biological networks (PPIs, Gene Ontology) adds context\cite{liu2015compound}. Early, mid, and late multimodal fusion techniques demonstrate that attention-based or intermediate fusion frequently performs better than naive concatenation\cite{stahlschmidt2022multimodal}.While knowledge infused architectures (such as GNNs on PPI, GO-hierarchy layers, or DrugCell style designs) integrate biological priors so that internal activations have pathway level significance, cross-attention aligns modalities\cite{elabd2024simple,mcdermott2019deep,samal2022opportunities}. Surveys frame this direction as essential to balance accuracy with actionable transparency\cite{chow2022predicting}.\\
\textbf{Strengths:} improved accuracy and out-of-distribution robustness, pathway/target-grounded explanations (\enquote{glass-box}).
\textbf{Weaknesses:} integration pipelines are complex, depend on quality/coverage of external knowledge bases.
\\ \\

\subsection{Comparative Summary}
\begin{table}[h]
  \centering
  \caption{Methods landscape for L1000-based MoA prediction: typical setup, strengths, and weaknesses.}
  \begin{tabular}{p{3.4cm} p{4.6cm} p{3.4cm} p{3.4cm}}
    \toprule
    \textbf{Family} & \textbf{Typical setup} & \textbf{Strengths} & \textbf{Weaknesses} \\
    \midrule
    Signature similarity (CMap/CD) &
    MODZ/CD signatures, retrieval/reversal scoring\cite{subramanian2017next,duan2016l1000cds2} &
    Simple, scalable, quick screening &
    Correlational, limited mechanism, sensitivity to noise \\
    \addlinespace
    Classical ML (RF/SVM/XGBoost) &
    Engineered features from L1000; optimized pipelines\cite{lu2021drug} &
    Fast; decent accuracy; interpretable features &
    Limited nonlinearity; weaker cross-context performance \\
    \addlinespace
    MLPs (deep baselines) &
    Expression-only deep encoders\cite{mcdermott2019deep} &
    Strong accuracy; flexible &
    Black-box; noise-sensitive without robust training \\
    \addlinespace
    GNNs / GO-structured nets &
    PPI/GO priors; message passing; intrinsic interpretability \cite{mcdermott2019deep,samal2022opportunities} &
    Mechanism grounding; pathway-level attributions &
    Data/knowledge hungry; integration complexity \\
    \addlinespace
    Attention/ Transformers / multimodal fusion &
    Cross-attention; expression+structure; knowledge-aware encoders \cite{pham2021deep,wu2022deep,stahlschmidt2022multimodal,elabd2024simple} &
    SOTA accuracy; better OOD; substructure–gene alignment &
    Computationally heavy; explanation validation required \\
    \bottomrule
  \end{tabular}
\end{table}

\subsection{Gaps and Opportunities}
(i) \textbf{Quantitative validation of explanations} remains limited. Many works rely on anecdotal or unreliable literature matches rather than faithfulness tests and perturbation-based validation.\\(ii) \textbf{Generalization to unseen contexts} (cell types, doses, time points) still lags, especially under structured, real-world noise that changes all the time.\\(iii) \textbf{Seamless knowledge ingestion} (ID harmonization; stable fusion of structure/PPIs/GO) requires standardized, reproducible pipelines, like a universal adapter.\\ These gaps motivate our objectives: standardized data/metadata handling (R2), knowledge-infused architectures (R3), and systematic baselines with robustness and interpretability evaluations (R1,R3).


%--- Chapter 3 ---%
\section{Methodology}
This research uses the \textbf{Design Science Research Methodology (DSRM)}, an established and a well known framework for creating and evaluating novel artifacts in information systems and computer science. The main,primary goal of using DSRM is to develop solutions to real-world problems through the design, implementation, and evaluation of a new technological artifact. Here, the \textbf{artifact} we talk in this project is the proposed computational framework for robust and interpretable Mechanism of Action (MoA) prediction.

The DSRM process is iterative and follows a set of logical steps, and here we see how they are applied for this project:
\begin{itemize}
    \item \textbf{1. Problem Identification and Motivation:} This first step involves carefully looking at the research problem and justifying the value of a solution. This was accomplished by completing the comprehensive literature review (Chapter 2), which identified the key challenges in the current available, existing methods. Throughout this paper, it is noted that the clinical translation of current models suffers by a lack of robustness to data noise, limited biological context, and poor model interpretability.

    \item \textbf{2. Define the Objectives for a Solution:}This step decides the objectives for the new artefact based on the issues that have been identified. The goals of the suggested framework, as stated in Section\ref{subsec:Objective of the Research},are to provide transparent, interpretable predictions, integrate external biological knowledge, and ensure robustness while achieving high predictive accuracy.

    \item \textbf{3. Design and Development:} This is the core, main, importaant construction phase where the artifact is created. This research will include the design and implementation of a multi-stage software pipeline in Python. Key development activities will include:
        \begin{itemize}
            \item Make a baseline and replicate the current procedures. 
            \item UUsing what is already known, a data-centric preprocessing module is implemented to reduce batch effects and normalise data.
            \item Constructing a knowledge graph from external databases (e.g., STRING, Gene Ontology).
            \item Building a novel deep learning architecture that integrates the knowledge graph and transcriptomic data.
            \item Integrating Explainable AI (XAI) algorithms into the output layer of the model.
        \end{itemize}

    \item \textbf{4. Demonstration:} In this step, the artifact is used to solve the problem. The developed framework will be applied to the LINCS L1000 dataset to predict the MoA for a curated set of chemical compounds, demonstrating its end-to-end functionality.

    \item \textbf{5. Evaluation:} This step involves measuring how well the artifact achieves and completes its objectives. The framework will be carefully evaluated using a two stepped approach:
        \begin{itemize}
            \item \textbf{Quantitative Evaluation:} The model's predictive performance (e.g., F1-score, accuracy) will be measured and compared against the baseline models identified in the literature review.
            \item \textbf{Qualitative Evaluation:}The XAI findings will be used to carry out case studies on specific medication predictions. The goal is to demonstrate that the model's explanations are physiologically sound and provide unique insights that correspond with existing pharmacology.
        \end{itemize}

    \item \textbf{6. Communication:} Sharing the findings with a larger audience is the last phase. The final research thesis and possibly a journal or conference publication will serve as official documentation and communication of the findings, the design of the framework, and its value.
\end{itemize}


%--- Chapter 4 ---%
\section{Progress}

\subsection{Current Progress}
This research project has moved forward in both its theoretical and practical stages. A solid basis has been laid by the work done at this point for the creation of the new computational framework.

\begin{itemize}
    \item \textbf{Systematic Literature Review (SLR) Completed:}A detailed SLR manuscript has been finished, and a complete manuscript outlining the results has been written.  In order to map the current state of interpretability techniques, identify important data-related challenges, and establish a performance baseline for current models, this review carefully examined 28 primary research articles.  The design and goals of the suggested framework are directly influenced by the review's findings.

    \item \textbf{Framework Development Initiated:} The software implementation's foundational work has begun. For a project to be modular, reproducible, and thoroughly documented, this preparatory stage is important. Among the key results are:
    \begin{itemize}
        \item \textbf{Technology Stack Selection:} Python has been chosen as the main language, along with PyTorch for deep learning, PyG (PyTorch Geometric) for graph neural networks, and RDKit for chemical structure handling.
        % \item \textbf{Project Scaffolding:} A modular codebase structure has been designed and created. This separates concerns for data preprocessing, model architecture, training, and evaluation, facilitating organized development.
        \item \textbf{Version Control and Experiment Tracking:} A Git repository has been established for robust version control. Furthermore, a strategy for documenting and maintaining different baseline models from the literature has been designed to ensure reproducible and fair comparison of results, and it is in progress to be implemented.
    \end{itemize}
\end{itemize}

\subsection{Future Time Plan}
The remainder of the research will focus on the development, evaluation, and documentation of the proposed framework. The following is a projected timeline to guide the project toward completion.

\begin{itemize}
    \item \textbf{Phase 1: Data Pipeline and Feature Engineering}
        \begin{itemize}
            \item Implement the data ingestion and cleaning pipeline for the LINCS L1000 dataset.
            \item Develop the module for constructing and integrating the biological knowledge graph.
            \item Generate and validate the final, enriched feature sets for the modeling phase.
        \end{itemize}
    
    \item \textbf{Phase 2: Model Development and Training}
        \begin{itemize}
            \item Implement and train the baseline models identified in the SLR for direct comparison.
            \item Design and implement the novel knowledge-infused deep learning architecture.
            \item Conduct extensive training experiments, including hyperparameter tuning and optimization.
        \end{itemize}
        
    \item \textbf{Phase 3: Evaluation and Analysis}
        \begin{itemize}
            \item Perform a rigorous quantitative evaluation of the final model against the baselines.
            \item Conduct a qualitative evaluation using the integrated XAI techniques to produce and analyze case studies for specific drug predictions.
            \item Synthesize all results and draw final conclusions.
        \end{itemize}
        
    \item \textbf{Phase 4: Thesis Finalization}
        \begin{itemize}
            \item Write the remaining chapters of the final research thesis (Methodology, Results, Discussion).
            \item Revise, proofread, and format the complete manuscript.
            \item Prepare for final submission and presentation of the research.
        \end{itemize}
\end{itemize}

%--- Chapter 5 ---%
\section{Summary}

This study tackles important issues with the LINCS L1000 dataset's computational analysis for drug discovery. Current models can predict a drug's Mechanism of Action (MoA), but they are often inaccurate and unreliable against data noise to be used confidently in a clinical setting.  The primary contribution of this work is the development of a consistent, end-to-end computational framework that tackles these issues. Three key components support the suggested framework: (1) a strong pipeline for preprocessing data to reduce technical noise; (2) the integration of external biological knowledge graphs to offer mechanistic context; and (3) the use of Explainable AI (XAI) to guarantee that all predictions are clear and understandable. The ultimate objective is to create a more dependable and useful scientific tool for speeding up drug discovery.

Right now, the project is at a crucial turning point. A thorough Systematic Literature Review, the first step, has been finished, and a complete manuscript has been written.  Performance baselines and the precise gaps in the literature that the suggested framework will fill have been successfully established by this review.  The framework's initial technical work, which includes choosing the technology stack, developing a modular codebase, and putting version control in place, has started in response to these findings.  According to the future time plan, the project is currently progressing from the literature analysis phase into the core development and implementation of the novel framework.

%--- References ---%
\bibliographystyle{plain}
\bibliography{references}

\end{document}
